{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-IqJAMkwnCF"
      },
      "source": [
        "# Advanced Retrieval with LangChain\n",
        "\n",
        "In the following notebook, we'll explore various methods of advanced retrieval using LangChain!\n",
        "\n",
        "We'll touch on:\n",
        "\n",
        "- Naive Retrieval\n",
        "- Best-Matching 25 (BM25)\n",
        "- Multi-Query Retrieval\n",
        "- Parent-Document Retrieval\n",
        "- Contextual Compression (a.k.a. Rerank)\n",
        "- Ensemble Retrieval\n",
        "- Semantic chunking\n",
        "\n",
        "We'll also discuss how these methods impact performance on our set of documents with a simple RAG chain.\n",
        "\n",
        "There will be two breakout rooms:\n",
        "\n",
        "- ðŸ¤ Breakout Room Part #1\n",
        "  - Task 1: Getting Dependencies!\n",
        "  - Task 2: Data Collection and Preparation\n",
        "  - Task 3: Setting Up QDrant!\n",
        "  - Task 4-10: Retrieval Strategies\n",
        "- ðŸ¤ Breakout Room Part #2\n",
        "  - Activity: Evaluate with Ragas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4rKP3hgHivpe"
      },
      "source": [
        "# ðŸ¤ Breakout Room Part #1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3xes8oT-xHN7"
      },
      "source": [
        "## Task 1: Getting Dependencies!\n",
        "\n",
        "We're going to need a few specific LangChain community packages, like OpenAI (for our [LLM](https://platform.openai.com/docs/models) and [Embedding Model](https://platform.openai.com/docs/guides/embeddings)) and Cohere (for our [Reranker](https://cohere.com/rerank)).\n",
        "\n",
        "> You do not need to run the following cells if you are running this notebook locally. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MkgFAXWVW3wm",
        "outputId": "636db35c-f05a-4038-ec7a-02360bef2dae"
      },
      "outputs": [],
      "source": [
        "#!pip install -qU langchain langchain-openai langchain-cohere rank_bm25"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKqYM4Eoxcov"
      },
      "source": [
        "We're also going to be leveraging [Qdrant's](https://qdrant.tech/documentation/frameworks/langchain/) (pronounced \"Quadrant\") VectorDB in \"memory\" mode (so we can leverage it locally in our colab environment)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "s6xav5CxYnML"
      },
      "outputs": [],
      "source": [
        "#!pip install -qU qdrant-client"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7OHJXzfyJyA"
      },
      "source": [
        "We'll also provide our OpenAI key, as well as our Cohere API key."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7LttlDQUYgSI",
        "outputId": "9dca95ab-4d02-4adf-ec3f-cb831326dc54"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import getpass\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI API Key:\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3iUahNiJyQbv",
        "outputId": "78bf06ef-2ee8-46c3-f73d-27958b4dd79b"
      },
      "outputs": [],
      "source": [
        "os.environ[\"COHERE_API_KEY\"] = getpass.getpass(\"Cohere API Key:\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "os.environ[\"RAGAS_APP_TOKEN\"] = getpass.getpass(\"Please enter your Ragas API key!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from langsmith import Client\n",
        "from langchain.callbacks.tracers import LangChainTracer\n",
        "from langchain.callbacks.manager import CallbackManager\n",
        "\n",
        "# Set up LangSmith environment\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = getpass.getpass(\"Enter your LangChain API Key:\")\n",
        "os.environ[\"LANGCHAIN_PROJECT\"] = \"retriever_comparison\"\n",
        "\n",
        "# Create callback manager\n",
        "langsmith_client = Client()\n",
        "tracer = LangChainTracer(project_name=\"retriever_comparison\")\n",
        "callback_manager = CallbackManager([tracer])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B0pDRFEWSXvh"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mw304iAFyRtl"
      },
      "source": [
        "## Task 2: Data Collection and Preparation\n",
        "\n",
        "We'll be using some reviews from the 4 movies in the John Wick franchise today to explore the different retrieval strategies.\n",
        "\n",
        "These were obtained from IMDB, and are available in the [AIM Data Repository](https://github.com/AI-Maker-Space/DataRepository)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xXKHcZmKzDwT"
      },
      "source": [
        "### Data Collection\n",
        "\n",
        "We can simply `wget` these from GitHub.\n",
        "\n",
        "You could use any review data you wanted in this step - just be careful to make sure your metadata is aligned with your choice."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vbbSIGtzX3dS",
        "outputId": "0ce6514e-2479-4001-af24-824f987ce599"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2025-03-01 21:38:09--  https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/jw1.csv\n",
            "Resolviendo raw.githubusercontent.com (raw.githubusercontent.com)... 2606:50c0:8003::154, 2606:50c0:8001::154, 2606:50c0:8002::154, ...\n",
            "Conectando con raw.githubusercontent.com (raw.githubusercontent.com)[2606:50c0:8003::154]:443... conectado.\n",
            "PeticiÃ³n HTTP enviada, esperando respuesta... 200 OK\n",
            "Longitud: 19628 (19K) [text/plain]\n",
            "Guardando como: â€˜john_wick_1.csvâ€™\n",
            "\n",
            "john_wick_1.csv     100%[===================>]  19,17K  --.-KB/s    en 0s      \n",
            "\n",
            "2025-03-01 21:38:10 (69,4 MB/s) - â€˜john_wick_1.csvâ€™ guardado [19628/19628]\n",
            "\n",
            "--2025-03-01 21:38:10--  https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/jw2.csv\n",
            "Resolviendo raw.githubusercontent.com (raw.githubusercontent.com)... 2606:50c0:8003::154, 2606:50c0:8000::154, 2606:50c0:8002::154, ...\n",
            "Conectando con raw.githubusercontent.com (raw.githubusercontent.com)[2606:50c0:8003::154]:443... conectado.\n",
            "PeticiÃ³n HTTP enviada, esperando respuesta... 200 OK\n",
            "Longitud: 14747 (14K) [text/plain]\n",
            "Guardando como: â€˜john_wick_2.csvâ€™\n",
            "\n",
            "john_wick_2.csv     100%[===================>]  14,40K  --.-KB/s    en 0s      \n",
            "\n",
            "2025-03-01 21:38:10 (62,0 MB/s) - â€˜john_wick_2.csvâ€™ guardado [14747/14747]\n",
            "\n",
            "--2025-03-01 21:38:11--  https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/jw3.csv\n",
            "Resolviendo raw.githubusercontent.com (raw.githubusercontent.com)... 2606:50c0:8001::154, 2606:50c0:8002::154, 2606:50c0:8000::154, ...\n",
            "Conectando con raw.githubusercontent.com (raw.githubusercontent.com)[2606:50c0:8001::154]:443... conectado.\n",
            "PeticiÃ³n HTTP enviada, esperando respuesta... 200 OK\n",
            "Longitud: 13888 (14K) [text/plain]\n",
            "Guardando como: â€˜john_wick_3.csvâ€™\n",
            "\n",
            "john_wick_3.csv     100%[===================>]  13,56K  --.-KB/s    en 0s      \n",
            "\n",
            "2025-03-01 21:38:11 (76,3 MB/s) - â€˜john_wick_3.csvâ€™ guardado [13888/13888]\n",
            "\n",
            "--2025-03-01 21:38:11--  https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/jw4.csv\n",
            "Resolviendo raw.githubusercontent.com (raw.githubusercontent.com)... 2606:50c0:8001::154, 2606:50c0:8000::154, 2606:50c0:8002::154, ...\n",
            "Conectando con raw.githubusercontent.com (raw.githubusercontent.com)[2606:50c0:8001::154]:443... conectado.\n",
            "PeticiÃ³n HTTP enviada, esperando respuesta... 200 OK\n",
            "Longitud: 15109 (15K) [text/plain]\n",
            "Guardando como: â€˜john_wick_4.csvâ€™\n",
            "\n",
            "john_wick_4.csv     100%[===================>]  14,75K  --.-KB/s    en 0s      \n",
            "\n",
            "2025-03-01 21:38:12 (67,2 MB/s) - â€˜john_wick_4.csvâ€™ guardado [15109/15109]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/jw1.csv -O john_wick_1.csv\n",
        "!wget https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/jw2.csv -O john_wick_2.csv\n",
        "!wget https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/jw3.csv -O john_wick_3.csv\n",
        "!wget https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/jw4.csv -O john_wick_4.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A92NC2QZzCsi"
      },
      "source": [
        "### Data Preparation\n",
        "\n",
        "We want to make sure all our documents have the relevant metadata for the various retrieval strategies we're going to be applying today.\n",
        "\n",
        "- Self-Query: Wants as much metadata as we can provide\n",
        "- Time-weighted: Wants temporal data\n",
        "\n",
        "> NOTE: While we're creating a temporal relationship based on when these movies came out for illustrative purposes, it needs to be clear that the \"time-weighting\" in the Time-weighted Retriever is based on when the document was *accessed* last - not when it was created."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "GshBjVRJZ6p8"
      },
      "outputs": [],
      "source": [
        "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "documents = []\n",
        "\n",
        "for i in range(1, 5):\n",
        "  loader = CSVLoader(\n",
        "      file_path=f\"john_wick_{i}.csv\",\n",
        "      metadata_columns=[\"Review_Date\", \"Review_Title\", \"Review_Url\", \"Author\", \"Rating\"]\n",
        "  )\n",
        "\n",
        "  movie_docs = loader.load()\n",
        "  for doc in movie_docs:\n",
        "\n",
        "    # Add the \"Movie Title\" (John Wick 1, 2, ...)\n",
        "    doc.metadata[\"Movie_Title\"] = f\"John Wick {i}\"\n",
        "\n",
        "    # convert \"Rating\" to an `int`, if no rating is provided - assume 0 rating\n",
        "    doc.metadata[\"Rating\"] = int(doc.metadata[\"Rating\"]) if doc.metadata[\"Rating\"] else 0\n",
        "\n",
        "    # newer movies have a more recent \"last_accessed_at\"\n",
        "    doc.metadata[\"last_accessed_at\"] = datetime.now() - timedelta(days=4-i)\n",
        "\n",
        "  documents.extend(movie_docs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gQphb6y0C0S"
      },
      "source": [
        "Let's look at an example document to see if everything worked as expected!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PkUkCf7DaMiq",
        "outputId": "e90bd5da-1d87-423b-838a-cb6efc16b199"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Document(metadata={'source': 'john_wick_1.csv', 'row': 0, 'Review_Date': '6 May 2015', 'Review_Title': ' Kinetic, concise, and stylish; John Wick kicks ass.\\n', 'Review_Url': '/review/rw3233896/?ref_=tt_urv', 'Author': 'lnvicta', 'Rating': 8, 'Movie_Title': 'John Wick 1', 'last_accessed_at': datetime.datetime(2025, 2, 26, 21, 38, 12, 352302)}, page_content=\": 0\\nReview: The best way I can describe John Wick is to picture Taken but instead of Liam Neeson it's Keanu Reeves and instead of his daughter it's his dog. That's essentially the plot of the movie. John Wick (Reeves) is out to seek revenge on the people who took something he loved from him. It's a beautifully simple premise for an action movie - when action movies get convoluted, they get bad i.e. A Good Day to Die Hard. John Wick gives the viewers what they want: Awesome action, stylish stunts, kinetic chaos, and a relatable hero to tie it all together. John Wick succeeds in its simplicity.\")"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "documents[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWaQpdHl0Gzc"
      },
      "source": [
        "## Task 3: Setting up QDrant!\n",
        "\n",
        "Now that we have our documents, let's create a QDrant VectorStore with the collection name \"JohnWick\".\n",
        "\n",
        "We'll leverage OpenAI's [`text-embedding-3-small`](https://openai.com/blog/new-embedding-models-and-api-updates) because it's a very powerful (and low-cost) embedding model.\n",
        "\n",
        "> NOTE: We'll be creating additional vectorstores where necessary, but this pattern is still extremely useful."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "NT8ihRJbYmMT"
      },
      "outputs": [],
      "source": [
        "from langchain_community.vectorstores import Qdrant\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
        "\n",
        "vectorstore = Qdrant.from_documents(\n",
        "    documents,\n",
        "    embeddings,\n",
        "    location=\":memory:\",\n",
        "    collection_name=\"JohnWick\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-x2SS4Rh0hiN"
      },
      "source": [
        "## Task 4: Naive RAG Chain\n",
        "\n",
        "Since we're focusing on the \"R\" in RAG today - we'll create our Retriever first."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NEH7X5Ai08FH"
      },
      "source": [
        "### R - Retrieval\n",
        "\n",
        "This naive retriever will simply look at each review as a document, and use cosine-similarity to fetch the 10 most relevant documents.\n",
        "\n",
        "> NOTE: We're choosing `10` as our `k` here to provide enough documents for our reranking process later"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "GFDPrNBtb72o"
      },
      "outputs": [],
      "source": [
        "naive_retriever = vectorstore.as_retriever(search_kwargs={\"k\" : 10})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MbBhyQjz06dx"
      },
      "source": [
        "### A - Augmented\n",
        "\n",
        "We're going to go with a standard prompt for our simple RAG chain today! Nothing fancy here, we want this to mostly be about the Retrieval process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "7uSz-Dbqcoki"
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "RAG_TEMPLATE = \"\"\"\\\n",
        "You are a helpful and kind assistant. Use the context provided below to answer the question.\n",
        "\n",
        "If you do not know the answer, or are unsure, say you don't know.\n",
        "\n",
        "Query:\n",
        "{question}\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\"\"\"\n",
        "\n",
        "rag_prompt = ChatPromptTemplate.from_template(RAG_TEMPLATE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BlRzpb231GGJ"
      },
      "source": [
        "### G - Generation\n",
        "\n",
        "We're going to leverage `gpt-3.5-turbo` as our LLM today, as - again - we want this to largely be about the Retrieval process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "c-1t9H60dJLg"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "chat_model = ChatOpenAI()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mg3QRGzA1M2x"
      },
      "source": [
        "### LCEL RAG Chain\n",
        "\n",
        "We're going to use LCEL to construct our chain.\n",
        "\n",
        "> NOTE: This chain will be exactly the same across the various examples with the exception of our Retriever!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "0bvstS7mdOW3"
      },
      "outputs": [],
      "source": [
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from operator import itemgetter\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "naive_retrieval_chain = (\n",
        "    # INVOKE CHAIN WITH: {\"question\" : \"<<SOME USER QUESTION>>\"}\n",
        "    # \"question\" : populated by getting the value of the \"question\" key\n",
        "    # \"context\"  : populated by getting the value of the \"question\" key and chaining it into the base_retriever\n",
        "    {\"context\": itemgetter(\"question\") | naive_retriever, \"question\": itemgetter(\"question\")}\n",
        "    # \"context\"  : is assigned to a RunnablePassthrough object (will not be called or considered in the next step)\n",
        "    #              by getting the value of the \"context\" key from the previous step\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    # \"response\" : the \"context\" and \"question\" values are used to format our prompt object and then piped\n",
        "    #              into the LLM and stored in a key called \"response\"\n",
        "    # \"context\"  : populated by getting the value of the \"context\" key from the previous step\n",
        "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "izKujhNb1ZG8"
      },
      "source": [
        "Let's see how this simple chain does on a few different prompts.\n",
        "\n",
        "> NOTE: You might think that we've cherry picked prompts that showcase the individual skill of each of the retrieval strategies - you'd be correct!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "LI-5ueEddku9",
        "outputId": "7f3cec18-5f4e-41bb-cf71-51ba0be5388e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Yes, people generally liked John Wick based on the reviews provided.'"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "naive_retrieval_chain.invoke({\"question\" : \"Did people generally like John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "43zdcdUydtXh",
        "outputId": "db874e67-f568-4ed1-b863-b7c17b387052"
      },
      "outputs": [],
      "source": [
        "res = naive_retrieval_chain.invoke({\"question\" : \"Do any reviews have a rating of 10? If so - can I have the URLs to those reviews?\"}, {\"tags\": [\"naive_retriever\"]})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "lpG6rlvvvKFq",
        "outputId": "a1b330b0-628e-41be-d829-9c1d55e781f5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"In John Wick, an ex-hitman comes out of retirement to seek vengeance against the gangsters who killed his dog and took everything from him. This sets off a chain of events where he unleashes destruction against those who try to stop him. It's a story filled with action, suspense, and intense fights.\""
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "naive_retrieval_chain.invoke({\"question\" : \"What happened in John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jsbfQmbr1leg"
      },
      "source": [
        "Overall, this is not bad! Let's see if we can make it better!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ft1vt8HPR16w"
      },
      "source": [
        "## Task 5: Best-Matching 25 (BM25) Retriever\n",
        "\n",
        "Taking a step back in time - [BM25](https://www.nowpublishers.com/article/Details/INR-019) is based on [Bag-Of-Words](https://en.wikipedia.org/wiki/Bag-of-words_model) which is a sparse representation of text.\n",
        "\n",
        "In essence, it's a way to compare how similar two pieces of text are based on the words they both contain.\n",
        "\n",
        "This retriever is very straightforward to set-up! Let's see it happen down below!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "qdF4wuj5R-cG"
      },
      "outputs": [],
      "source": [
        "from langchain_community.retrievers import BM25Retriever\n",
        "\n",
        "bm25_retriever = BM25Retriever.from_documents(documents)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KIjJlBQ8drKH"
      },
      "source": [
        "We'll construct the same chain - only changing the retriever."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "WR15EQG7SLuw"
      },
      "outputs": [],
      "source": [
        "bm25_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | bm25_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Gi-yXCDdvJk"
      },
      "source": [
        "Let's look at the responses!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "oY9qzmm3SOrF",
        "outputId": "4d4f450f-5978-460f-f242-b32407868353"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Overall, opinions on the John Wick movies seem to be mixed. Some people really enjoy the action and style of the films, while others find them lacking in substance and plot. It ultimately depends on personal preferences.'"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bm25_retrieval_chain.invoke({\"question\" : \"Did people generally like John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "igfinyneSQkh",
        "outputId": "9752d4a9-dd16-45b1-f63f-a76e93a05eb3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"I'm sorry, but the reviews provided do not have a rating of 10.\""
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bm25_retrieval_chain.invoke({\"question\" : \"Do any reviews have a rating of 10? If so - can I have the URLs to those reviews?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "w0H7pV_USSMQ",
        "outputId": "bdead654-3109-4143-9a30-e1d6ca8dc534"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'In John Wick, the protagonist, portrayed by Keanu Reeves, is a retired hitman seeking vengeance for the death of his puppy, a final gift from his deceased wife. The movie is known for its beautifully choreographed action sequences and emotional depth despite being categorized as an action flick.'"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bm25_retrieval_chain.invoke({\"question\" : \"What happened in John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvg5xHaUdxCl"
      },
      "source": [
        "It's not clear that this is better or worse - but the `I don't know` isn't great!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-dcbFn2vpZF"
      },
      "source": [
        "## Task 6: Contextual Compression (Using Reranking)\n",
        "\n",
        "Contextual Compression is a fairly straightforward idea: We want to \"compress\" our retrieved context into just the most useful bits.\n",
        "\n",
        "There are a few ways we can achieve this - but we're going to look at a specific example called reranking.\n",
        "\n",
        "The basic idea here is this:\n",
        "\n",
        "- We retrieve lots of documents that are very likely related to our query vector\n",
        "- We \"compress\" those documents into a smaller set of *more* related documents using a reranking algorithm.\n",
        "\n",
        "We'll be leveraging Cohere's Rerank model for our reranker today!\n",
        "\n",
        "All we need to do is the following:\n",
        "\n",
        "- Create a basic retriever\n",
        "- Create a compressor (reranker, in this case)\n",
        "\n",
        "That's it!\n",
        "\n",
        "Let's see it in the code below!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "psHvO2K1v_ZQ"
      },
      "outputs": [],
      "source": [
        "from langchain.retrievers.contextual_compression import ContextualCompressionRetriever\n",
        "from langchain_cohere import CohereRerank\n",
        "\n",
        "compressor = CohereRerank(model=\"rerank-english-v3.0\")\n",
        "compression_retriever = ContextualCompressionRetriever(\n",
        "    base_compressor=compressor, base_retriever=naive_retriever)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_TA9RB2x-j7P"
      },
      "source": [
        "Let's create our chain again, and see how this does!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "1BXqmxvHwX6T"
      },
      "outputs": [],
      "source": [
        "contextual_compression_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | compression_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "V3iGpokswcBb",
        "outputId": "f15d2aa1-5e8b-417d-f623-eb835d072e59"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Based on the reviews provided, it seems that people generally liked the first John Wick movie. The reviews mention that it was a remarkable, surprising film that caught viewers off guard and that it was something special with elaborate action sequences.'"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "contextual_compression_retrieval_chain.invoke({\"question\" : \"Did people generally like John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "7u_k0i4OweUd",
        "outputId": "be5fccc8-2352-4189-c524-bbeaa28cf799"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"Yes, there is a review with a rating of 10. Here is the URL to that review: '/review/rw4854296/?ref_=tt_urv'.\""
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "contextual_compression_retrieval_chain.invoke({\"question\" : \"Do any reviews have a rating of 10? If so - can I have the URLs to those reviews?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "zn1EqaGqweXN",
        "outputId": "42bc5972-4164-46eb-f49d-4272f39bb89b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"In John Wick, after resolving his issues with the Russian mafia, John Wick returns home. However, the mobster Santino D'Antonio visits him with his marker asking for help. John Wick refuses, and Santino blows up his house. To honor the marker, John Wick is asked to kill Santino's sister in Rome. Once he completes the task, a contract is put on him, attracting professional killers from all over. Wick promises to kill Santino in revenge.\""
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "contextual_compression_retrieval_chain.invoke({\"question\" : \"What happened in John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OEbT0g2S-mZ4"
      },
      "source": [
        "We'll need to rely on something like Ragas to help us get a better sense of how this is performing overall - but it \"feels\" better!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qqbghrBEQNn5"
      },
      "source": [
        "## Task 7: Multi-Query Retriever\n",
        "\n",
        "Typically in RAG we have a single query - the one provided by the user.\n",
        "\n",
        "What if we had....more than one query!\n",
        "\n",
        "In essence, a Multi-Query Retriever works by:\n",
        "\n",
        "1. Taking the original user query and creating `n` number of new user queries using an LLM.\n",
        "2. Retrieving documents for each query.\n",
        "3. Using all unique retrieved documents as context\n",
        "\n",
        "So, how is it to set-up? Not bad! Let's see it down below!\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "pfM26ReXQjzU"
      },
      "outputs": [],
      "source": [
        "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
        "\n",
        "multi_query_retriever = MultiQueryRetriever.from_llm(\n",
        "    retriever=naive_retriever, llm=chat_model\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "1vRc129jQ5WW"
      },
      "outputs": [],
      "source": [
        "multi_query_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | multi_query_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "CGgNuOb3Q3M9",
        "outputId": "c5273ecf-da35-40b8-fbdb-0f8beab425f7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Yes, people generally liked John Wick based on the positive reviews provided.'"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "multi_query_retrieval_chain.invoke({\"question\" : \"Did people generally like John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "aAlSthxrRDBC",
        "outputId": "230ff807-23ae-4d25-8d11-cfdbed0b77cb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"I don't know.\""
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "multi_query_retrieval_chain.invoke({\"question\" : \"Do any reviews have a rating of 10? If so - can I have the URLs to those reviews?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "Uv1mpCK8REs4",
        "outputId": "00fbc22a-ed9b-4613-9695-0b179e3f8369"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'In John Wick, Keanu Reeves plays the character of John Wick, a retired assassin who comes out of retirement seeking revenge after some Russian mobsters steal his car, kill his dog, and inadvertently push him back into the world of assassins. The story follows John as he goes on a vengeful killing spree against those who wronged him.'"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "multi_query_retrieval_chain.invoke({\"question\" : \"What happened in John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDEawBf_d_3G"
      },
      "source": [
        "## Task 8: Parent Document Retriever\n",
        "\n",
        "A \"small-to-big\" strategy - the Parent Document Retriever works based on a simple strategy:\n",
        "\n",
        "1. Each un-split \"document\" will be designated as a \"parent document\" (You could use larger chunks of document as well, but our data format allows us to consider the overall document as the parent chunk)\n",
        "2. Store those \"parent documents\" in a memory store (not a VectorStore)\n",
        "3. We will chunk each of those documents into smaller documents, and associate them with their respective parents, and store those in a VectorStore. We'll call those \"child chunks\".\n",
        "4. When we query our Retriever, we will do a similarity search comparing our query vector to the \"child chunks\".\n",
        "5. Instead of returning the \"child chunks\", we'll return their associated \"parent chunks\".\n",
        "\n",
        "Okay, maybe that was a few steps - but the basic idea is this:\n",
        "\n",
        "- Search for small documents\n",
        "- Return big documents\n",
        "\n",
        "The intuition is that we're likely to find the most relevant information by limiting the amount of semantic information that is encoded in each embedding vector - but we're likely to miss relevant surrounding context if we only use that information.\n",
        "\n",
        "Let's start by creating our \"parent documents\" and defining a `RecursiveCharacterTextSplitter`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "qJ53JJuMd_ZH"
      },
      "outputs": [],
      "source": [
        "from langchain.retrievers import ParentDocumentRetriever\n",
        "from langchain.storage import InMemoryStore\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from qdrant_client import QdrantClient, models\n",
        "\n",
        "parent_docs = documents\n",
        "child_splitter = RecursiveCharacterTextSplitter(chunk_size=200)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oOpXfVUH3gL3"
      },
      "source": [
        "We'll need to set up a new QDrant vectorstore - and we'll use another useful pattern to do so!\n",
        "\n",
        "> NOTE: We are manually defining our embedding dimension, you'll need to change this if you're using a different embedding model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rzFc-_9HlGQ-",
        "outputId": "223662dd-c36f-42f7-d1b0-b086e571484e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_69029/3574430551.py:8: LangChainDeprecationWarning: The class `Qdrant` was deprecated in LangChain 0.0.37 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-qdrant package and should be used instead. To use it run `pip install -U :class:`~langchain-qdrant` and import as `from :class:`~langchain_qdrant import Qdrant``.\n",
            "  parent_document_vectorstore = Qdrant(\n"
          ]
        }
      ],
      "source": [
        "client = QdrantClient(location=\":memory:\")\n",
        "\n",
        "client.create_collection(\n",
        "    collection_name=\"full_documents\",\n",
        "    vectors_config=models.VectorParams(size=1536, distance=models.Distance.COSINE)\n",
        ")\n",
        "\n",
        "parent_document_vectorstore = Qdrant(\n",
        "    collection_name=\"full_documents\", embeddings=OpenAIEmbeddings(model=\"text-embedding-3-small\"), client=client\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sf_g95FA3s6w"
      },
      "source": [
        "Now we can create our `InMemoryStore` that will hold our \"parent documents\" - and build our retriever!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "BpWVjPf4fLUp"
      },
      "outputs": [],
      "source": [
        "store = InMemoryStore()\n",
        "\n",
        "parent_document_retriever = ParentDocumentRetriever(\n",
        "    vectorstore = parent_document_vectorstore,\n",
        "    docstore=store,\n",
        "    child_splitter=child_splitter\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KoYmSWfE32Zo"
      },
      "source": [
        "By default, this is empty as we haven't added any documents - let's add some now!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "iQ2ZzfKigMZc"
      },
      "outputs": [],
      "source": [
        "parent_document_retriever.add_documents(parent_docs, ids=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bI7Tip1335rE"
      },
      "source": [
        "We'll create the same chain we did before - but substitute our new `parent_document_retriever`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "Qq_adt2KlSqp"
      },
      "outputs": [],
      "source": [
        "parent_document_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | parent_document_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jNolUVQb4Apt"
      },
      "source": [
        "Let's give it a whirl!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "TXB5i89Zly5W",
        "outputId": "94c240be-7c5b-4c58-9eee-56d93285a054"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Some people liked John Wick, while others did not. It seems to have received mixed reviews based on the opinions shared.'"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "parent_document_retrieval_chain.invoke({\"question\" : \"Did people generally like John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "V5F1T-wNl3cg",
        "outputId": "9b81e72e-5db7-4b8a-b25b-400ea0df5335"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Yes, there is a review with a rating of 10 for the movie \"John Wick 3\". Here is the URL to that review: \\'/review/rw4854296/?ref_=tt_urv\\'.'"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "parent_document_retrieval_chain.invoke({\"question\" : \"Do any reviews have a rating of 10? If so - can I have the URLs to those reviews?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "ZqARszGzvGcG",
        "outputId": "8867f83c-db13-4db4-d57f-9bd51d32cd8a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'In John Wick, the protagonist, played by Keanu Reeves, is a retired assassin who comes out of retirement after his dog is killed in the first movie. In the second movie, he is forced back into the world of assassination when an Italian crime lord calls in a favor. Wick then goes on a violent journey to fulfill this task, traveling to Italy, Canada, and Manhattan, and killing numerous assassins along the way.'"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "parent_document_retrieval_chain.invoke({\"question\" : \"What happened in John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B41cj42s4DPM"
      },
      "source": [
        "Overall, the performance *seems* largely the same. We can leverage a tool like [Ragas]() to more effectively answer the question about the performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUrIBKl_TwS9"
      },
      "source": [
        "## Task 9: Ensemble Retriever\n",
        "\n",
        "In brief, an Ensemble Retriever simply takes 2, or more, retrievers and combines their retrieved documents based on a rank-fusion algorithm.\n",
        "\n",
        "In this case - we're using the [Reciprocal Rank Fusion](https://plg.uwaterloo.ca/~gvcormac/cormacksigir09-rrf.pdf) algorithm.\n",
        "\n",
        "Setting it up is as easy as providing a list of our desired retrievers - and the weights for each retriever."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "8j7jpZsKTxic"
      },
      "outputs": [],
      "source": [
        "from langchain.retrievers import EnsembleRetriever\n",
        "\n",
        "retriever_list = [bm25_retriever, naive_retriever, parent_document_retriever, compression_retriever, multi_query_retriever]\n",
        "equal_weighting = [1/len(retriever_list)] * len(retriever_list)\n",
        "\n",
        "ensemble_retriever = EnsembleRetriever(\n",
        "    retrievers=retriever_list, weights=equal_weighting\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kpo9Psl5hhJ-"
      },
      "source": [
        "We'll pack *all* of these retrievers together in an ensemble."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "KZ__EZwpUKkd"
      },
      "outputs": [],
      "source": [
        "ensemble_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | ensemble_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSsvHpRMj24L"
      },
      "source": [
        "Let's look at our results!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "0lMvqL88UQI-",
        "outputId": "d86dd5f7-0a13-4836-c0ce-cc4c431fd889"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"Based on the reviews provided, it seems that in general, people liked John Wick. The movie received positive reviews praising the action sequences, Keanu Reeves' performance, and the world-building aspect of the film. Overall, the feedback from the reviews suggests that the movie was well-received by the audience.\""
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ensemble_retrieval_chain.invoke({\"question\" : \"Did people generally like John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "MNFWLYECURI1",
        "outputId": "b17973b5-66a9-4481-97d5-880b5754b5c5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Yes, there is a review with a rating of 10. Here is the URL to that review:\\n- Reviewer: ymyuseda\\n- Rating: 10\\n- URL: [Link to Review](https://www.imdb.com/review/rw4854296/?ref_=tt_urv)'"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ensemble_retrieval_chain.invoke({\"question\" : \"Do any reviews have a rating of 10? If so - can I have the URLs to those reviews?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "A7qbHfWgUR4c",
        "outputId": "f7373144-59ef-4fc7-b75d-ca00e7df881e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'In the movie \"John Wick,\" an ex-hit-man comes out of retirement to track down the gangsters that killed his dog and took everything from him. With the untimely death of his beloved wife still bitter in his mouth, he seeks vengeance. Wick finds himself dragged into an impossible task as every killer in the business dreams of cornering him. As he goes on a rampage seeking revenge, he becomes the target of hit men and bounty-hunting killers. The plot revolves around his relentless vendetta against those who have wronged him.'"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ensemble_retrieval_chain.invoke({\"question\" : \"What happened in John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MopbkNJAXVaN"
      },
      "source": [
        "## Task 10: Semantic Chunking\n",
        "\n",
        "While this is not a retrieval method - it *is* an effective way of increasing retrieval performance on corpora that have clean semantic breaks in them.\n",
        "\n",
        "Essentially, Semantic Chunking is implemented by:\n",
        "\n",
        "1. Embedding all sentences in the corpus.\n",
        "2. Combining or splitting sequences of sentences based on their semantic similarity based on a number of [possible thresholding methods](https://python.langchain.com/docs/how_to/semantic-chunker/):\n",
        "  - `percentile`\n",
        "  - `standard_deviation`\n",
        "  - `interquartile`\n",
        "  - `gradient`\n",
        "3. Each sequence of related sentences is kept as a document!\n",
        "\n",
        "Let's see how to implement this!\n",
        "\n",
        "> NOTE: You do not need to run this cell if you're running this locally"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1dHeB-yGXneL",
        "outputId": "efc59105-518a-4134-9228-d98b8a97e08e"
      },
      "outputs": [],
      "source": [
        "#!pip install -qU langchain_experimental"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U9ciZbFEldv_"
      },
      "source": [
        "We'll use the `percentile` thresholding method for this example which will:\n",
        "\n",
        "Calculate all distances between sentences, and then break apart sequences of setences that exceed a given percentile among all distances."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "66EIEWiEYl5y"
      },
      "outputs": [],
      "source": [
        "from langchain_experimental.text_splitter import SemanticChunker\n",
        "\n",
        "semantic_chunker = SemanticChunker(\n",
        "    embeddings,\n",
        "    breakpoint_threshold_type=\"percentile\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YqoKmz12mhRW"
      },
      "source": [
        "Now we can split our documents."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "ROcV7o68ZIq7"
      },
      "outputs": [],
      "source": [
        "semantic_documents = semantic_chunker.split_documents(documents)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L8-LNC-Xmjex"
      },
      "source": [
        "Let's create a new vector store."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "h3sl9QjyZhIe"
      },
      "outputs": [],
      "source": [
        "semantic_vectorstore = Qdrant.from_documents(\n",
        "    semantic_documents,\n",
        "    embeddings,\n",
        "    location=\":memory:\",\n",
        "    collection_name=\"JohnWickSemantic\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eh_r_-LHmmKn"
      },
      "source": [
        "We'll use naive retrieval for this example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "odVyDUHwZftc"
      },
      "outputs": [],
      "source": [
        "semantic_retriever = semantic_vectorstore.as_retriever(search_kwargs={\"k\" : 10})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mkeiv_ojmp6G"
      },
      "source": [
        "Finally we can create our classic chain!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "xWE_0J0mZveG"
      },
      "outputs": [],
      "source": [
        "semantic_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | semantic_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5pfjLQ3ms9_"
      },
      "source": [
        "And view the results!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "0lN2j-e4Z0SD",
        "outputId": "ef483e21-7200-4dfc-b8bf-aed4f23587b2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Based on the reviews provided, it seems that people generally like John Wick.'"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "semantic_retrieval_chain.invoke({\"question\" : \"Did people generally like John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "xdqfBH1SZ3f9",
        "outputId": "ed62b2d1-7586-46cc-aaf4-c54192a56155"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Yes, there is a review with a rating of 10 for the movie \"John Wick 3.\" Here is the URL to that review: \\'/review/rw4854296/?ref_=tt_urv\\''"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "semantic_retrieval_chain.invoke({\"question\" : \"Do any reviews have a rating of 10? If so - can I have the URLs to those reviews?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "rAcAObZnZ4o6",
        "outputId": "3f1cade3-41e4-4e42-ef71-048dd18e5e3a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'John Wick is a movie about a retired assassin named John Wick seeking revenge on those who killed his dog and stole his car. It is a beautifully simple premise for an action movie filled with awesome action, stylish stunts, and a relatable hero.'"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "semantic_retrieval_chain.invoke({\"question\" : \"What happened in John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xk2n3-pnVWDJ"
      },
      "source": [
        "# ðŸ¤ Breakout Room Part #2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2SkJLYwMVZkj"
      },
      "source": [
        "#### ðŸ—ï¸ Activity #1\n",
        "\n",
        "Your task is to evaluate the various Retriever methods against eachother.\n",
        "\n",
        "You are expected to:\n",
        "\n",
        "1. Create a \"golden dataset\"\n",
        " - Use Synthetic Data Generation (powered by Ragas, or otherwise) to create this dataset\n",
        "2. Evaluate each retriever with *retriever specific* Ragas metrics\n",
        " - Semantic Chunking is not considered a retriever method and will not be required for marks, but you may find it useful to do a \"semantic chunking on\" vs. \"semantic chunking off\" comparision between them\n",
        "3. Compile these in a list and write a small paragraph about which is best for this particular data and why.\n",
        "\n",
        "Your analysis should factor in:\n",
        "  - Cost\n",
        "  - Latency\n",
        "  - Performance\n",
        "\n",
        "> NOTE: This is **NOT** required to be completed in class. Please spend time in your breakout rooms creating a plan before moving on to writing code."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWAr16a5XMub"
      },
      "source": [
        "##### HINTS:\n",
        "\n",
        "- LangSmith provides detailed information about latency and cost."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "tgDICngKXLGK"
      },
      "outputs": [],
      "source": [
        "from ragas.llms import LangchainLLMWrapper\n",
        "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "generator_llm = LangchainLLMWrapper(ChatOpenAI(model=\"gpt-4o-mini\"))\n",
        "generator_embeddings = LangchainEmbeddingsWrapper(OpenAIEmbeddings())\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8510f72eb88944c2bbb953399c51cfee",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying SummaryExtractor:   0%|          | 0/44 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "201fb59d5ffb439dae64bb8f1224d11a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying CustomNodeFilter:   0%|          | 0/100 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Node 21f344b0-ccca-4416-9615-c841196a5f9c does not have a summary. Skipping filtering.\n",
            "Node 9f822eca-4e3d-4789-a2d2-cad27cef583d does not have a summary. Skipping filtering.\n",
            "Node fc89e06b-eb12-4896-a715-1afcd2f72bab does not have a summary. Skipping filtering.\n",
            "Node af5f3d3d-0ff1-4595-bc71-05ffb446432c does not have a summary. Skipping filtering.\n",
            "Node d37c2185-3f8c-48f2-b1f3-bd0e66071170 does not have a summary. Skipping filtering.\n",
            "Node a62ad3ec-b243-4306-8c08-b88c3f1942ee does not have a summary. Skipping filtering.\n",
            "Node 3a9292f6-10db-4113-b819-927129cf909e does not have a summary. Skipping filtering.\n",
            "Node e02b6b2d-2414-4714-aeeb-c10bbc8c376d does not have a summary. Skipping filtering.\n",
            "Node 1e467949-568b-48c0-8173-51cadd13e965 does not have a summary. Skipping filtering.\n",
            "Node fb84941a-7d64-43f2-8e44-694f177d64ca does not have a summary. Skipping filtering.\n",
            "Node 2fa9d1b8-1721-4318-a18f-338c3743e5f9 does not have a summary. Skipping filtering.\n",
            "Node 23199e27-3719-49af-a53b-ff415eae9d97 does not have a summary. Skipping filtering.\n",
            "Node f75750c3-886d-423a-998e-502542cc3a74 does not have a summary. Skipping filtering.\n",
            "Node 21da834c-b92e-4d22-8d56-59e40a8d5038 does not have a summary. Skipping filtering.\n",
            "Node efad2ba1-acbc-4d07-aa81-8371f1a5022f does not have a summary. Skipping filtering.\n",
            "Node aca6832d-86e8-4009-b1c8-87c747bfdb48 does not have a summary. Skipping filtering.\n",
            "Node 4c53271d-a6ff-4f48-95de-0b6b1397fb27 does not have a summary. Skipping filtering.\n",
            "Node 02567d42-8681-450c-a496-3f4d6107f1e6 does not have a summary. Skipping filtering.\n",
            "Node 7f57cfaf-84dd-42a5-be0f-8556f8848f75 does not have a summary. Skipping filtering.\n",
            "Node 95dde388-83f8-41f3-8dac-b043b33ffda0 does not have a summary. Skipping filtering.\n",
            "Node d4b303fe-b98a-4a78-bc0a-05fe0eb33138 does not have a summary. Skipping filtering.\n",
            "Node 385b492a-a731-4fda-8782-fb50fdbdd34a does not have a summary. Skipping filtering.\n",
            "Node 3a651ec3-0622-4eb5-843b-7e2297626f30 does not have a summary. Skipping filtering.\n",
            "Node cce3d9fb-f1a9-41e1-ad46-301effcb0665 does not have a summary. Skipping filtering.\n",
            "Node 00bd99b7-e67c-444f-bc2a-885b67f291ed does not have a summary. Skipping filtering.\n",
            "Node 76e423d6-4b55-4c20-9eb1-9c57ee52cda1 does not have a summary. Skipping filtering.\n",
            "Node a2271f4d-3f6c-4030-b615-d6b84446e53b does not have a summary. Skipping filtering.\n",
            "Node dc7e1f2a-9236-47fc-9da5-8ec6b0fe8974 does not have a summary. Skipping filtering.\n",
            "Node 4b62225b-e349-4ba9-b8b6-f0ac6cc71150 does not have a summary. Skipping filtering.\n",
            "Node 674f1365-b30b-4076-8b11-5563a8dc380a does not have a summary. Skipping filtering.\n",
            "Node e428b152-bb33-4a12-905a-4efd3828cb75 does not have a summary. Skipping filtering.\n",
            "Node a87428f3-d869-4c7e-b257-293b20a7c1fc does not have a summary. Skipping filtering.\n",
            "Node 3422d4ed-2cdd-46ca-bb91-30c7b96eb01c does not have a summary. Skipping filtering.\n",
            "Node 5766a62d-aab1-41a0-9c70-d9fc1350e813 does not have a summary. Skipping filtering.\n",
            "Node 652efb8c-895d-4098-908a-0e1f29fe3e1b does not have a summary. Skipping filtering.\n",
            "Node e3a49e1b-aad6-4137-b39a-e664e85205ea does not have a summary. Skipping filtering.\n",
            "Node 8fa2c855-c699-4812-a6c5-1222d3a13233 does not have a summary. Skipping filtering.\n",
            "Node 96198d7a-7cb0-48b9-92a4-b8f45ba9ac35 does not have a summary. Skipping filtering.\n",
            "Node 407e9713-846b-4c7d-b7f8-10042dcf0f81 does not have a summary. Skipping filtering.\n",
            "Node 39d3a4ad-51ae-4a70-81d5-a08418febcd5 does not have a summary. Skipping filtering.\n",
            "Node 9ccf76a8-fe24-4743-a543-7a330774a923 does not have a summary. Skipping filtering.\n",
            "Node dda44e71-3708-4474-a89c-fee0f399c1a8 does not have a summary. Skipping filtering.\n",
            "Node b386c471-46cd-4408-a07a-57a28f680c88 does not have a summary. Skipping filtering.\n",
            "Node 09c4d553-bf94-4082-9bbe-b4e70b04b14b does not have a summary. Skipping filtering.\n",
            "Node 3c397018-a1d6-4fba-91e9-ec85054c1d48 does not have a summary. Skipping filtering.\n",
            "Node 0a40ddf7-31d6-4fb6-92dd-3aeebf2f3f95 does not have a summary. Skipping filtering.\n",
            "Node bc7526ad-0a1f-426a-ae0e-4c0d7bd16853 does not have a summary. Skipping filtering.\n",
            "Node 89d22532-9414-4074-8029-a779fe0fb82b does not have a summary. Skipping filtering.\n",
            "Node 2ad049c5-5ef8-4018-8d7b-3d5f5c671089 does not have a summary. Skipping filtering.\n",
            "Node bcf70480-62ef-4d24-a3d2-7da5877bb4f6 does not have a summary. Skipping filtering.\n",
            "Node 8c310102-f3ef-42a5-a6cc-e6ca740b06ea does not have a summary. Skipping filtering.\n",
            "Node 0beff701-e8da-4030-aab8-09fd4d47b89c does not have a summary. Skipping filtering.\n",
            "Node 0c843461-00cb-4111-8a4f-2268710158f6 does not have a summary. Skipping filtering.\n",
            "Node cbbb33dd-7b61-4a13-8507-bcf678aba5f0 does not have a summary. Skipping filtering.\n",
            "Node 7c82a0d7-4796-424a-ad53-24dcf071e111 does not have a summary. Skipping filtering.\n",
            "Node e79447ff-4446-432e-ad9f-5c7f617f966c does not have a summary. Skipping filtering.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9a7a2024f8ab46d0895c9a1b16ea432f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying [EmbeddingExtractor, ThemesExtractor, NERExtractor]:   0%|          | 0/244 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "152a737ab5664e838de006c33801647d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying OverlapScoreBuilder:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c524b15ec54c43bebccd973b9d7de799",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating personas:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "03a40bc0d34f4d47ae232ceeea9071e2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating Scenarios:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "97b9b075baaa4e36989470b75251bb84",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating Samples:   0%|          | 0/10 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from ragas.testset import TestsetGenerator\n",
        "\n",
        "generator = TestsetGenerator(llm=generator_llm, embedding_model=generator_embeddings)\n",
        "dataset = generator.generate_with_langchain_docs(documents, testset_size=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Ragas Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [],
      "source": [
        "def chain_evaluation(dataset,chain, tag):\n",
        "    from ragas import evaluate\n",
        "    from ragas.llms import LangchainLLMWrapper\n",
        "    from ragas import EvaluationDataset\n",
        "\n",
        "    from ragas.metrics import LLMContextRecall, Faithfulness, FactualCorrectness, ResponseRelevancy, ContextEntityRecall, NoiseSensitivity\n",
        "    from ragas import evaluate, RunConfig\n",
        "\n",
        "    for test_row in dataset:\n",
        "        response = chain.invoke({\"question\" : test_row.eval_sample.user_input}, {\"tags\": [tag]})\n",
        "        test_row.eval_sample.response = response[\"response\"].content\n",
        "        test_row.eval_sample.retrieved_contexts = [context.page_content for context in response[\"context\"]]\n",
        "\n",
        "\n",
        "    evaluator_llm = LangchainLLMWrapper(ChatOpenAI(model=\"gpt-4o-mini\"))\n",
        "\n",
        "    evaluation_dataset = EvaluationDataset.from_pandas(dataset.to_pandas())\n",
        "\n",
        "    custom_run_config = RunConfig(timeout=360)\n",
        "\n",
        "    result = evaluate(\n",
        "        dataset= evaluation_dataset,\n",
        "        metrics=[LLMContextRecall(), Faithfulness(), FactualCorrectness(), ResponseRelevancy(), ContextEntityRecall(), NoiseSensitivity()],\n",
        "        llm= evaluator_llm,\n",
        "        run_config=custom_run_config\n",
        "    )\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f737ea4397b0478da883a0839bdad6bb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/60 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "naive_result = chain_evaluation(dataset,naive_retrieval_chain,'naive_retriever')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'context_recall': 0.8333, 'faithfulness': 0.8248, 'factual_correctness': 0.2690, 'answer_relevancy': 0.5718, 'context_entity_recall': 0.4567, 'noise_sensitivity_relevant': 0.4914}"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "naive_result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d468058ac60346adbefd4574f1934b12",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/60 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "bm25_result = chain_evaluation(dataset,bm25_retrieval_chain,'bm25_retriever')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'context_recall': 0.4333, 'faithfulness': 0.6778, 'factual_correctness': 0.2720, 'answer_relevancy': 0.5814, 'context_entity_recall': 0.3117, 'noise_sensitivity_relevant': 0.3118}"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bm25_result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "78ab29fd0bf04a2287fd8c38c0c822e6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/60 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "contextual_compression_result = chain_evaluation(dataset,contextual_compression_retrieval_chain,'contextual_compression_retriever')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "19fb7c59258a4b86883f80da842ad68c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/60 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Exception raised in Job[47]: TimeoutError()\n"
          ]
        }
      ],
      "source": [
        "multi_query_result = chain_evaluation(dataset,multi_query_retrieval_chain, 'multi_query_retriever')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d4a7d3f0de194e59b0df48e7ee165e2a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/60 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "parent_document_result = chain_evaluation(dataset,parent_document_retrieval_chain,'parent_document_retriever')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f575e000ed8e476b8a6891bf440c7f85",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/60 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "ensemble_result = chain_evaluation(dataset,ensemble_retrieval_chain,'ensemble_retriever')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5907297eb0a24c03b63f7a19d9cc961a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/60 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "semantic_result = chain_evaluation(dataset,semantic_retrieval_chain,'semantic_retriever')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Retriever</th>\n",
              "      <th>context_recall</th>\n",
              "      <th>faithfulness</th>\n",
              "      <th>factual_correctness</th>\n",
              "      <th>answer_relevancy</th>\n",
              "      <th>context_entity_recall</th>\n",
              "      <th>noise_sensitivity_relevant</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Naive</td>\n",
              "      <td>0.8333</td>\n",
              "      <td>0.8248</td>\n",
              "      <td>0.269</td>\n",
              "      <td>0.5718</td>\n",
              "      <td>0.4567</td>\n",
              "      <td>0.4914</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>BM25</td>\n",
              "      <td>0.4333</td>\n",
              "      <td>0.6778</td>\n",
              "      <td>0.272</td>\n",
              "      <td>0.5814</td>\n",
              "      <td>0.3117</td>\n",
              "      <td>0.3118</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Contextual Compression</td>\n",
              "      <td>0.4833</td>\n",
              "      <td>0.7387</td>\n",
              "      <td>0.368</td>\n",
              "      <td>0.4768</td>\n",
              "      <td>0.4383</td>\n",
              "      <td>0.3639</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Multi Query</td>\n",
              "      <td>0.9667</td>\n",
              "      <td>0.6557</td>\n",
              "      <td>0.345</td>\n",
              "      <td>0.6746</td>\n",
              "      <td>0.4583</td>\n",
              "      <td>0.6188</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Parent Document</td>\n",
              "      <td>0.4917</td>\n",
              "      <td>0.7083</td>\n",
              "      <td>0.237</td>\n",
              "      <td>0.4784</td>\n",
              "      <td>0.2650</td>\n",
              "      <td>0.2583</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Ensemble</td>\n",
              "      <td>0.8667</td>\n",
              "      <td>0.6650</td>\n",
              "      <td>0.361</td>\n",
              "      <td>0.4692</td>\n",
              "      <td>0.3917</td>\n",
              "      <td>0.5830</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Semantic</td>\n",
              "      <td>0.8583</td>\n",
              "      <td>0.5367</td>\n",
              "      <td>0.268</td>\n",
              "      <td>0.5745</td>\n",
              "      <td>0.3917</td>\n",
              "      <td>0.5958</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                Retriever  context_recall  faithfulness  factual_correctness  \\\n",
              "0                   Naive          0.8333        0.8248                0.269   \n",
              "1                    BM25          0.4333        0.6778                0.272   \n",
              "2  Contextual Compression          0.4833        0.7387                0.368   \n",
              "3             Multi Query          0.9667        0.6557                0.345   \n",
              "4         Parent Document          0.4917        0.7083                0.237   \n",
              "5                Ensemble          0.8667        0.6650                0.361   \n",
              "6                Semantic          0.8583        0.5367                0.268   \n",
              "\n",
              "   answer_relevancy  context_entity_recall  noise_sensitivity_relevant  \n",
              "0            0.5718                 0.4567                      0.4914  \n",
              "1            0.5814                 0.3117                      0.3118  \n",
              "2            0.4768                 0.4383                      0.3639  \n",
              "3            0.6746                 0.4583                      0.6188  \n",
              "4            0.4784                 0.2650                      0.2583  \n",
              "5            0.4692                 0.3917                      0.5830  \n",
              "6            0.5745                 0.3917                      0.5958  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Convert dictionary to DataFrame\n",
        "df = pd.read_csv('Evaluation_Metrics.csv')\n",
        "\n",
        "df.rename(columns={'Unnamed: 0': 'Retriever'}, inplace=True)\n",
        "\n",
        "display(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cost and Latency using Langsmith\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Metrics for  naive_retriever\n",
            "Average Latency: 0.54 seconds\n",
            "Total Cost: $0.073190\n",
            "Average Cost per Run: $0.000523\n",
            "-------------------------------------------------------------------------------------\n",
            "Metrics for  bm25_retriever\n",
            "Average Latency: 0.36 seconds\n",
            "Total Cost: $0.030544\n",
            "Average Cost per Run: $0.000218\n",
            "-------------------------------------------------------------------------------------\n",
            "Metrics for  contextual_compression_retriever\n",
            "Average Latency: 0.73 seconds\n",
            "Total Cost: $0.027270\n",
            "Average Cost per Run: $0.000182\n",
            "-------------------------------------------------------------------------------------\n",
            "Metrics for  multi_query_retriever\n",
            "Average Latency: 0.91 seconds\n",
            "Total Cost: $0.104331\n",
            "Average Cost per Run: $0.000497\n",
            "-------------------------------------------------------------------------------------\n",
            "Metrics for  parent_document_retriever\n",
            "Average Latency: 0.46 seconds\n",
            "Total Cost: $0.014522\n",
            "Average Cost per Run: $0.000104\n",
            "-------------------------------------------------------------------------------------\n",
            "Metrics for  ensemble_retriever\n",
            "Average Latency: 1.09 seconds\n",
            "Total Cost: $0.126852\n",
            "Average Cost per Run: $0.000470\n",
            "-------------------------------------------------------------------------------------\n",
            "Metrics for  semantic_retriever\n",
            "Average Latency: 0.53 seconds\n",
            "Total Cost: $0.061524\n",
            "Average Cost per Run: $0.000439\n",
            "-------------------------------------------------------------------------------------\n",
            "\n",
            "--- RETRIEVER COMPARISON SUMMARY ---\n",
            "Retriever Type                 Avg Latency (s) Avg Cost ($)    Total Cost ($)  Run Count \n",
            "-------------------------------------------------------------------------------------\n",
            "naive_retriever                0.54            0.000523        0.073190        140       \n",
            "bm25_retriever                 0.36            0.000218        0.030544        140       \n",
            "contextual_compression_retriever 0.73            0.000182        0.027270        150       \n",
            "multi_query_retriever          0.91            0.000497        0.104331        210       \n",
            "parent_document_retriever      0.46            0.000104        0.014522        140       \n",
            "ensemble_retriever             1.09            0.000470        0.126852        270       \n",
            "semantic_retriever             0.53            0.000439        0.061524        140       \n"
          ]
        }
      ],
      "source": [
        "from langsmith import Client\n",
        "\n",
        "# Initialize the client\n",
        "client = Client()\n",
        "\n",
        "# Function to get runs by tag with corrected filter syntax\n",
        "def get_runs_by_tag(tag, project_name=\"retriever_comparison\", limit=10):\n",
        "    try:\n",
        "        # List runs with the specified tag using the correct filter syntax\n",
        "        runs = client.list_runs(\n",
        "            project_name=project_name,\n",
        "            filter=f'has(tags, \"{tag}\")'\n",
        "        )\n",
        "        return list(runs)  # Convert iterator to list\n",
        "    except Exception as e:\n",
        "        print(f\"Error retrieving runs: {str(e)}\")\n",
        "        return []\n",
        "\n",
        "# Get runs for each retriever type\n",
        "retriever_types = [\"naive_retriever\", \"bm25_retriever\", \"contextual_compression_retriever\", \n",
        "                  \"multi_query_retriever\", \"parent_document_retriever\", \n",
        "                  \"ensemble_retriever\", \"semantic_retriever\"]\n",
        "\n",
        "# Create a dictionary to store results\n",
        "results = {}\n",
        "\n",
        "for tag in retriever_types:\n",
        "    runs = get_runs_by_tag(tag)\n",
        "    \n",
        "    if runs:\n",
        "        \n",
        "        # Calculate average latency and total cost\n",
        "        total_latency = 0\n",
        "        total_cost = 0\n",
        "        count = 0\n",
        "        \n",
        "        for run in runs:\n",
        "            # Calculate latency\n",
        "            if hasattr(run, 'end_time') and hasattr(run, 'start_time'):\n",
        "                latency = (run.end_time - run.start_time).total_seconds()\n",
        "                total_latency += latency\n",
        "                count += 1\n",
        "            \n",
        "            # Extract cost information - directly from the total_cost attribute\n",
        "            if hasattr(run, 'total_cost') and run.total_cost is not None:\n",
        "                total_cost += float(run.total_cost)\n",
        "        \n",
        "        # Calculate averages\n",
        "        avg_latency = total_latency / count if count > 0 else 0\n",
        "        avg_cost = total_cost / count if count > 0 else 0\n",
        "        \n",
        "        # Store results\n",
        "        results[tag] = {\n",
        "            'avg_latency': avg_latency,\n",
        "            'total_cost': total_cost,\n",
        "            'avg_cost': avg_cost,\n",
        "            'run_count': count\n",
        "        }\n",
        "        print(\"Metrics for \", tag)\n",
        "        print(f\"Average Latency: {avg_latency:.2f} seconds\")\n",
        "        print(f\"Total Cost: ${total_cost:.6f}\")\n",
        "        print(f\"Average Cost per Run: ${avg_cost:.6f}\")\n",
        "        print(\"-\" * 85)\n",
        "    else:\n",
        "        print(f\"No runs found with tag '{tag}'\")\n",
        "\n",
        "# Print summary table\n",
        "print(\"\\n--- RETRIEVER COMPARISON SUMMARY ---\")\n",
        "print(f\"{'Retriever Type':<30} {'Avg Latency (s)':<15} {'Avg Cost ($)':<15} {'Total Cost ($)':<15} {'Run Count':<10}\")\n",
        "print(\"-\" * 85)\n",
        "for tag, data in results.items():\n",
        "    print(f\"{tag:<30} {data['avg_latency']:<15.2f} {data['avg_cost']:<15.6f} {data['total_cost']:<15.6f} {data['run_count']:<10}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Performance Analysis**\n",
        "\n",
        "### **Cost Efficiency**\n",
        "The **Parent Document Retriever** has the lowest cost both per retrieval (**$0.000104**) and total (**$0.014522**), making it the most budget-friendly option.\n",
        "\n",
        "### **Latency**\n",
        "The **BM25 Retriever** has the lowest average latency (**0.36s**), making it the fastest retriever.\n",
        "\n",
        "### **Performance**\n",
        "- **Best Context Recall**: **Multi Query Retriever** (**0.9667**), meaning it retrieves the most relevant contextual information.\n",
        "- **Best Faithfulness**: **Naive Retriever** (**0.8248**), generating responses most aligned with retrieved content.\n",
        "- **Best Factual Correctness**: **Contextual Compression Retriever** (**0.368**), ensuring higher factual accuracy.\n",
        "- **Best Answer Relevancy**: **Multi Query Retriever** (**0.6746**), producing the most relevant responses to user queries.\n",
        "- **Best Context Entity Recall**: **Multi Query Retriever** (**0.4583**), capturing the required entities more effectively.\n",
        "- **Least Noise Sensitivity**: **Parent Document Retriever** (**0.2583**), being less affected by irrelevant context.\n",
        "\n",
        "---\n",
        "\n",
        "## **Best Choice**\n",
        "- If **cost** is the main concern, **Parent Document Retriever** is the best choice.\n",
        "- If **speed** is the priority, **BM25 Retriever** is the fastest option.\n",
        "- For the **best overall balance of accuracy, relevancy, and contextual recall**, **Multi Query Retriever** is the most effective, despite being more expensive and slower.\n",
        "- If **factual correctness** is key, **Contextual Compression Retriever** offers the best balance between accuracy and faithfulness.\n",
        "- If **a compromise between cost and performance** is needed, **Contextual Compression Retriever** is a solid choice.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
